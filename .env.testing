# RAD Gateway Test Configuration
# For local testing with Ollama
# Usage: cp .env.testing .env && go run ./cmd/rad-gateway

# Server Configuration
RAD_LISTEN_ADDR=:8090
RAD_LOG_LEVEL=debug
RAD_ENVIRONMENT=testing
RAD_RETRY_BUDGET=2

# Test API Keys (for local testing only)
# Format: name:key,name:key,...
RAD_API_KEYS=\
  test:test_key_for_local_testing_only_001,\
  dev:dev_key_for_local_testing_only_002,\
  admin:admin_key_for_local_testing_only_003,\
  readonly:readonly_test_key_004

# Database (SQLite for local testing)
RAD_DB_DRIVER=sqlite
RAD_DB_DSN=radgateway_test.db

# Redis (optional - leave empty to disable)
# RAD_REDIS_ADDR=localhost:6379
# RAD_REDIS_PASSWORD=
# RAD_REDIS_DB=0

# =============================================================================
# OLLAMA LOCAL PROVIDER CONFIGURATION
# =============================================================================

# Ollama runs OpenAI-compatible API on localhost:11434
# This allows testing the gateway without external API keys

OLLAMA_ENABLED=true
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama  # Ollama doesn't require auth, but we need something

# Ollama Model Mapping
# Maps gateway model names to Ollama model names
OLLAMA_MODEL_LLAMA3=llama3.2:latest
OLLAMA_MODEL_MISTRAL=mistral:latest
OLLAMA_MODEL_CODELLAMA=codellama:latest

# =============================================================================
# EXTERNAL PROVIDER API KEYS (Optional for testing)
# Leave empty to skip external providers during testing
# =============================================================================

# OpenAI (https://platform.openai.com/api-keys)
# OPENAI_API_KEY=sk-test-...

# Anthropic (https://console.anthropic.com/settings/keys)
# ANTHROPIC_API_KEY=sk-ant-test-...

# Google Gemini (https://makersuite.google.com/app/apikey)
# GEMINI_API_KEY=test-...

# =============================================================================
# MODEL ROUTING CONFIGURATION
# =============================================================================

# Default: Route all models to Ollama for local testing
# Uncomment external providers if you have API keys

# Model routes are defined in config.Load() - see internal/config/config.go
# To customize, modify the loadModelRoutes() function

# =============================================================================
# JWT CONFIGURATION (for admin endpoints)
# =============================================================================

JWT_ACCESS_SECRET=test-access-secret-for-local-testing-only-do-not-use-in-production
JWT_REFRESH_SECRET=test-refresh-secret-for-local-testing-only-do-not-use-in-production

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Cedar authorization (disabled for testing)
RAD_CEDAR_ENABLED=false

# mTLS (disabled for testing)
RAD_MTLS_ENABLED=false

# =============================================================================
# TESTING CHECKLIST
# =============================================================================

# 1. Start Ollama locally:
#    $ ollama serve
#    $ ollama pull llama3.2:latest
#
# 2. Start the gateway:
#    $ cp .env.testing .env
#    $ go run ./cmd/rad-gateway
#
# 3. Test the API:
#    $ curl http://localhost:8090/health
#    $ curl -H "Authorization: Bearer test_key_for_local_testing_only_001" \
#           http://localhost:8090/v1/models
#    $ curl -X POST http://localhost:8090/v1/chat/completions \
#           -H "Authorization: Bearer test_key_for_local_testing_only_001" \
#           -H "Content-Type: application/json" \
#           -d '{"model":"llama3.2","messages":[{"role":"user","content":"Hello"}]}'
#
# 4. Admin endpoints (JWT required):
#    # Get token first
#    $ curl -X POST http://localhost:8090/v1/auth/login \
#           -H "Content-Type: application/json" \
#           -d '{"username":"admin","password":"admin"}'
#
# =============================================================================
